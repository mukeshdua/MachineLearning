{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Logistic Regression Example \n",
    "#### http://www.data-mania.com/blog/logistic-regression-example-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from pylab import rcParams\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression on the Titanic dataset\n",
    "* We will put this data into a Pandas DataFrame, called __`titanic`__, and name each of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('data/titanic.csv')\n",
    "titanic.columns = 'PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked'.split()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VARIABLE DESCRIPTIONS\n",
    "\n",
    "Survived - Survival (0 = No; 1 = Yes)<br>\n",
    "Pclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)<br>\n",
    "Name - Name<br>\n",
    "Sex - Sex<br>\n",
    "Age - Age<br>\n",
    "SibSp - Number of Siblings/Spouses Aboard<br>\n",
    "Parch - Number of Parents/Children Aboard<br>\n",
    "Ticket - Ticket Number<br>\n",
    "Fare - Passenger Fare (British pound)<br>\n",
    "Cabin - Cabin<br>\n",
    "Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking that your target variable is binary\n",
    "Since we are building a model to predict survival of passangers from the Titanic, our target is going to be \"Survived\" variable from the titanic dataframe. To make sure that it's a binary variable, let's use Seaborn's __`countplot()`__ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(x='Survived',data=titanic, palette='hls');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we the __Survived__ variable is binary (0 - did not survive / 1 - survived)\n",
    "\n",
    "### Checking for missing values\n",
    "It's easy to check for missing values by calling the __`isnull()`__ method, and the __`sum()`__ method off of that, to return a tally of all the True values that are returned by the __`isnull()`__ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many records are there in the DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ok, so there are only 891 rows in the titanic data frame\n",
    "* __Cabin__ is almost all missing values, so we can drop that variable completely\n",
    "* What about age? Age seems like a relevant predictor for survival, right? We'd want to keep the variables, but it has 177 missing values. Yikes!! We are going to need to find a way to approximate for those missing values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing values\n",
    "### Dropping missing values\n",
    "So let's just go ahead and drop all the variables that aren't relevant for predicting survival. We should at least keep the following:\n",
    "- __Survived__ - This variable is obviously relevant\n",
    "- __Pclass__ - Does a passenger's class on the boat affect their survivability?\n",
    "- __Sex__ - Could a passenger's gender impact their survival rate?\n",
    "- __Age__ - Does a person's age impact their survival rate?\n",
    "- __SibSp__ - Does the number of relatives on the boat (that are siblings or a spouse) affect a person survivability? Probability\n",
    "- __Parch__ - Does the number of relatives on the boat (that are children or parents) affect a person survivability? Probability\n",
    "- __Fare__ - Does the fare a person paid effect his survivability? Maybe - let's keep it.\n",
    "- __Embarked__ - Does a person's point of embarkation matter? It depends on how the boat was filled... Let's keep it.\n",
    "\n",
    "* What about a person's name, ticket number, and passenger ID number? They're irrelavant for predicting survivability. And as you recall, the cabin variable is almost all missing values, so we can just drop all of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = titanic.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we have the DataFrame reduced down to only relevant variables, but now we need to deal with the missing values in the age variable.\n",
    "\n",
    "### Imputing missing values\n",
    "Let's look at how passenger age is related to their class as a passenger on the ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(x='Pclass', y='Age', data=titanic_data, palette='hls');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking roughly, we could say that the younger a passenger is, the more likely it is for them to be in 3rd class. The older a passenger is, the more likely it is for them to be in 1st class. So there is a loose relationship between these variables. So, let's write a function that approximates a passengers age, based on their class. From the box plot, it looks like the average age of 1st class passengers is about 37, 2nd class passengers is 29, and 3rd class pasengers is 24.\n",
    "\n",
    "So let's write a function that finds each null value in the Age variable, and for each null, checks the value of the Pclass and assigns an age value according to the average age of passengers in that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_approx(cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]\n",
    "    class_to_age = { 1: 37, 2: 29, 3: 24 }\n",
    "    \n",
    "    if pd.isnull(Age):\n",
    "        return class_to_age[Pclass]\n",
    "    else:\n",
    "        return Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply the function and check again for null values, we see that there are no more null values in the age variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Age'] = titanic_data[['Age', 'Pclass']].apply(age_approx, axis=1)\n",
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 2 null values in the embarked variable. We can drop those 2 records without losing too much important information from our dataset, so we will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.dropna(inplace=True)\n",
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categorical variables to a dummy variables\n",
    "The next thing we need to do is reformat our variables so that they work with the model. Specifically, we need to reformat the __Sex__ and __Embarked__ variables into numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = pd.get_dummies(titanic_data['Sex'], drop_first=True)\n",
    "gender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embark_location = pd.get_dummies(titanic_data['Embarked'], drop_first=True)\n",
    "embark_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.drop(['Sex', 'Embarked'], axis=1, inplace=True)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dmy = pd.concat([titanic_data, gender, embark_location], axis=1)\n",
    "titanic_dmy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataset with all the variables in the correct format!\n",
    "\n",
    "### Checking for independence between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(titanic_dmy.corr());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fare__ and __Pclass__ are not independent of each other, so I am going to drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dmy.drop(['Fare', 'Pclass'], axis=1, inplace=True)\n",
    "titanic_dmy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking that your dataset size is sufficient\n",
    "We have 6 predictive features that remain. The rule of thumb is 50 records per feature...so we need to have at least 300 records in this dataset. Let's check again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dmy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have 889 records so we are fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_dmy.iloc[:,1:].values\n",
    "y = titanic_dmy.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remember that correct predictions are on the diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "137 / (137 + 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
